# Memory
- Program must be brought (from disk)  into memory and placed within a process for it to be run
- Main memory and registers are only storage CPU can access directly
- Memory unit only sees a stream of addresses + read requests, or address + data and write requests
- Register access in one CPU clock (or less)
- Main memory can take many cycles, causing a processor stall
- Cache sits between main memory and CPU registers
- Protection of memory required to ensure correct operation
- Each process has a separate memory space
## Base and Limit registers
- We need to defined the range of legal addresses that a process may access. This is ensured by two registers:
    - Base Register: Holds the smallest legal physical memory address.
    - Limit Register: specifies the size of the range.
For e.g. if the base register holds 1250 and limit register is 356, then the program can access all addresses from 1250 to 1605(inclusive)
- CPU must check every memory access generated in user mode to be sure it is between base and limit for that user
# Logical vs Physical address
- Logical address – generated by the CPU; also referred to as virtual address
- Physical address – address seen by the memory unit
- Logical and physical addresses are the same in compile-time and load-time address-binding schemes;
- logical (virtual) and physical addresses differ in execution-time address-binding scheme
- Logical address space is the set of all logical addresses generated by a program
- Physical address space is the set of all physical addresses generated by a program
# Memory managememt Unit
- Hardware device that at run time maps virtual to physical address
- Base register now called relocation register
- The user program deals with logical addresses; it never sees the real physical addresses.
- A value in the relocation register is added to every address generated by a user process at the time it is sent to memory
## Techniques
- There are two Memory Management Techniques: Contiguous, and Non-Contiguous.
-  In Contiguous Technique, executing process must be loaded entirely in main-memory.
- Contiguous Technique can be divided into:
    - Fixed (or static) partitioning
    - Variable (or dynamic) partitioning
# Partition
## Fixed partition
- It can be used to load more than one processes into the main memory.
- In this technique, the main memory is divided into partitions of equal or different sizes.
- The operating system always resides in the first partition while the other partitions can be used to store user processes.
- In fixed partitioning,
    - The partitions cannot overlap.
    - A process must be contiguously present in a partition for the execution.
### disadvantages
1. Internal Fragmentation
---
- If the size of the process is lesser then the total size of the partition
- some size of the partition get wasted and remain unused.
---
2. External Fragmentation
---
- The total unused space of various partitions cannot be used to load the processes.
---
3. Limitation on the size of the process
---
- Process of size greater than size of partition in Main Memory cannot be accommodated.
---
4. Limitation on Degree of Multiprogramming
---
- let n1 be partitions in RAM and n2 are the number of processes, then condition n2<=n1 must be fulfilled.
---
## Dymanic partition
- Dynamic partitioning tries to overcome the problems caused by fixed partitioning.
- In this technique, the partition size is not declared initially.
- It is declared at the time of process loading.
- The first partition is reserved for the operating system. The remaining space is divided into parts.
- The size of each partition will be equal to the size of the process.
- The partition size varies according to the need of the process so that the internal fragmentation can be avoided.
### good bad
- Advantages
---
- No Internal Fragmentation
- No Limitation on the size of the process
- Degree of multiprogramming is dynamic
----
- Disadvateges
----
- External Fragmentation
---
## Algorithms
1. First-fit:
    - Allocate the first hole that is big enough
2. Best-fit:
    - Allocate the smallest hole that is big enough;
    - must search entire list, unless ordered by size
    - Produces the smallest leftover hole
3. Worst-fit:  Allocate the largest hole;
    - must also search entire list
    - Produces the largest leftover hole
- First-fit and best-fit better than worst-fit in terms of speed and storage utilization
## Non-Contagious
- Physical  address space of a process can be noncontiguous as
    - Avoids external fragmentation
    - Avoids problem of varying sized memory chunks
# Paging
- Paging is a storage mechanism used to retrieve processes from the secondary storage into the main memory in the form of pages.
- Pages of the process are brought into the main memory only when they are required otherwise they reside in the secondary storage.
- We Divide physical memory into fixed-sized blocks called frames.
    - Size is power of 2, between 512 bytes and 16 Mbytes
- We Divide logical memory into blocks of same size called pages
## good bad
- advantages
---
- Large virtual memory.
- More efficient use of memory.
- There is no limit on degree of multiprogramming.
---
- disadvantages
---
- Number of tables and the amount of processor overhead for handling page interrupts are greater
---
## Demand Paging
- A demand paging system is quite similar to a paging system
- It swapps where processes reside in secondary memory and pages are loaded only on demand, not in advance.
- When a context switch occurs,
    - the operating system does not copy any of the old program’s pages out to the disk or any of the new program’s pages into the main memory.
    - Instead, it just begins executing the new program after loading the first page
    - also fetches that program’s pages as they are referenced.
## Page Fault
- While executing a program, if the program references a page which is not available in the main memory.
- Processor treats this invalid memory reference as a page fault
- Then transfers control from the program to the operating system to demand the page back into the memory.
## Page replacement
- if there is a free page in memory, use it
- if not,
    - select a victim frame
    - write the victim out to disk
    - read the desired page into the now free frame
    - update page tables
    - restart the process
- Main objective of a good replacement algorithm is to achieve
    - a low page fault rate
    - insure that heavily used pages stay in memory
    - the replaced page should not be needed for some time
    - to reduce latency of a page fault
    - efficient code
    - replace pages that do not need to be written out
### reference string
- Reference string is the sequence of pages being referenced
- If user has the following sequence of addresses 123, 215, 600, 1234, 76, 96
- If the page size is 100, then the reference string is 1, 2, 6, 12, 0, 0
### FIFO
- Oldest page in main memory is the one which will be selected for replacement.
- Very simple to implement as it keeps a list of
    - victims are chosen from the tail
    - new pages in are placed at the head
#### Issues
- Poor replacement policy
- Evicts the oldest page in the system
- usually a heavily used variable should be around for a long time
- FIFO replaces the oldest page - perhaps the one with the heavily used variable
- FIFO does not consider page usage
#### Belady’s Anomaly
- For some page replacement algorithms, the page fault rate may increase as the number of allocated frames increases.
### Optimal Page Replacement
- Replace the page that will not be referenced for the longest time
- This gives the lowest possible fault rate
### Least Recently Used (LRU)
- replace the page in memory that has not been accessed for the longest time
- Optimal policy looking back in time
    - as opposed to forward in time
    - fortunately, programs tend to follow similar behavior
#### issues
- requires special hardware support
- to track last page access
    1. Counters
        - the page with the smallest “time” value is replaced
    2. stack
        - keep a stack of references
        - on every reference to a page, move it to top of stack
        - page at bottom of stack is next one to be replaced
## Thrashing vs swapping
### Swapping
- Memory management technique where entire processes are moved between main memory and secondary storage
- It optimizes memory usage and allow multiple processes to run concurrently.
- Key characteristics of swapping:
    - Entire process is moved in and out of main memory
    - Used to manage limited physical memory resources
    - Relatively controlled and predictable process
    - Helps in multiprogramming and resource allocation
    - Typically occurs when the system has insufficient memory to run all active processes

### Thrashing
- It is a critical performance degradation scenario that occurs when a computer spends more time swapping pages than executing actual instructions.
- Key characteristics of thrashing:
    - Happens when the system is severely overloaded with memory demands
    - Occurs when the working set of processes exceeds available physical memory
    - Leads to excessive page faults and constant disk I/O
    - Dramatically reduces system performance
    - Can cause the system to become nearly unresponsive
## Page table
- To run a program of size N pages, need to find N free frames and load program
- for that we Set up a page table to translate logical to physical addresses
Backing store likewise split into pages
Still have Internal fragmentation
## Translation Lookaside Buffer (TLB)
- The entire page table was kept in the main memory to overcome this size issue.
- but the problem here is two main memory references are required:
    - To find the frame number
    - To go to the address specified by frame number
- To overcome this problem a high-speed cache is set up for page table entries called a TLB
- It is used to keep track of recently used transactions.
- Working
---
- Given a virtual address, the processor examines the TLB if a page table entry is present (TLB hit),
    - the frame number is retrieved and the real address is formed.
    - If a page table entry is not found in the TLB (TLB miss), the page number is used as an index while processing the page table.
    - TLB first checks if the page is already in main memory,
    - if not in main memory a page fault is issued then the TLB is updated to include the new page entry.
---
$$\large
EAT = \text{Hit ratio}\times (Atlb+Amm)+\text{Miss ratio}(Atlb+2\times Amm)
$$
EAT = Effective Access Time
`Atlb` = Access time of TLB
`Amm` = Access time of Main Memory

---
# Segmentation
- Memory-management scheme that supports user view of memory
- A program is a collection of segments
- A segment is a logical unit such as:
    1. main program
    2. procedure
    3. function
    4. method
	5. object
	6. local variables, global variables
	7. common block
	8. stack
	9. symbol table
	10. arrays
- Operating system doesn't care about the User's view of the process.
- It may divide the same function into different pages and those pages may or may not be loaded at the same time into the memory.
- This decreases the efficiency of the system.
## Architecture
- Logical address consists of a two tuple:
    - `<segment-number, offset>`
- Segment table – maps two-dimensional physical addresses; each table entry has:
    1. base – contains the starting physical address where the segments reside in memory
    2. limit – specifies the length of the segment
    3. Segment-table base register (STBR) points to the segment table’s location in memory
    4. Segment-table length register (STLR) indicates number of segments used by a program;
- segment number s is legal if `s < STLR`
- Since segments vary in length, memory allocation is a dynamic storage-allocation problem
## good bad
- Advantages
---
- No internal fragmentation
- Average Segment Size is larger than the actual page size.
- Less overhead
- It is easier to relocate segments than entire address space.
- The segment table is of lesser size as compare to the page table in paging.
----
- disadvantages
---
- It can have external fragmentation.
- it is difficult to allocate contiguous memory to variable sized partition.
- Costly memory management algorithms.
---
